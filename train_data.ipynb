{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y (first 5): [3, 3, 4, 3, 3]\n",
      "y_train_scaled (first 5): [ 1.  50.5 50.5 50.5 50.5]\n",
      "y_test_scaled (first 5): [50.5  1.  50.5 50.5 50.5]\n",
      "Random Forest R²: 73.2609448329315\n",
      "Random Forest MAE: 5.509595366379311\n",
      "Random Forest Predictions (first 5): [32.185  3.97  50.995 50.5   50.5  ]\n",
      "XGBoost R²: 72.06781411308548\n",
      "XGBoost MAE: 6.242448676214553\n",
      "XGBoost Predictions (first 5): [38.334854  6.728392 49.7944   50.621037 50.476856]\n",
      "Random Forest Top 10 Features:\n",
      " EmpLastSalaryHikePercent        0.233694\n",
      "EmpEnvironmentSatisfaction      0.225229\n",
      "YearsSinceLastPromotion         0.187019\n",
      "ExperienceYearsInCurrentRole    0.067274\n",
      "EmpDepartment_Development       0.050266\n",
      "EmpWorkLifeBalance              0.043151\n",
      "EmpJobRole_Developer            0.023623\n",
      "Age                             0.018357\n",
      "YearsWithCurrManager            0.017079\n",
      "EmpHourlyRate                   0.014326\n",
      "dtype: float64\n",
      "XGBoost Top 10 Features:\n",
      " EmpDepartment_Development               0.148851\n",
      "YearsSinceLastPromotion                 0.144860\n",
      "EmpLastSalaryHikePercent                0.143854\n",
      "EmpJobRole_Developer                    0.112171\n",
      "EmpEnvironmentSatisfaction              0.083122\n",
      "ExperienceYearsInCurrentRole            0.069938\n",
      "EmpWorkLifeBalance                      0.021796\n",
      "EmpDepartment_Research & Development    0.017827\n",
      "OverTime_Yes                            0.017441\n",
      "EmpJobRole_Senior Developer             0.014950\n",
      "dtype: float32\n",
      "Models, scalers, and mappings saved to 'backend/' directory.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    data = pd.read_csv('INX_Future_Inc_Employee_Performance_CDS_Project2_Data_V1.8.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'INX_Future_Inc_Employee_Performance_CDS_Project2_Data_V1.8.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Drop non-useful columns\n",
    "X = data.drop(columns=['PerformanceRating', 'EmpNumber'])\n",
    "y = data['PerformanceRating']\n",
    "\n",
    "# Convert categorical features to numerical with one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Save feature names for app.py\n",
    "feature_names = X.columns.tolist()\n",
    "os.makedirs('backend', exist_ok=True)\n",
    "with open('backend/feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_names, f)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling (for X)\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train)\n",
    "X_test_scaled = feature_scaler.transform(X_test)\n",
    "\n",
    "# Target Scaling (for y, to 1-100 range)\n",
    "target_scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Debug: Verify target scaling\n",
    "print(\"Original y (first 5):\", y.head().tolist())\n",
    "print(\"y_train_scaled (first 5):\", y_train_scaled[:5])\n",
    "print(\"y_test_scaled (first 5):\", y_test_scaled[:5])\n",
    "\n",
    "# Define and train Random Forest with increased flexibility\n",
    "model_rf = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)  # Increased max_depth\n",
    "model_rf.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Define and train XGBoost\n",
    "model_xg = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "model_xg.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "rf_pred = model_rf.predict(X_test_scaled)\n",
    "xg_pred = model_xg.predict(X_test_scaled)\n",
    "print(\"Random Forest R²:\", r2_score(y_test_scaled, rf_pred) * 100)\n",
    "print(\"Random Forest MAE:\", mean_absolute_error(y_test_scaled, rf_pred))\n",
    "print(\"Random Forest Predictions (first 5):\", rf_pred[:5])\n",
    "print(\"XGBoost R²:\", r2_score(y_test_scaled, xg_pred) * 100)\n",
    "print(\"XGBoost MAE:\", mean_absolute_error(y_test_scaled, xg_pred))\n",
    "print(\"XGBoost Predictions (first 5):\", xg_pred[:5])\n",
    "\n",
    "# Feature Importance\n",
    "rf_importance = pd.Series(model_rf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "xg_importance = pd.Series(model_xg.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "print(\"Random Forest Top 10 Features:\\n\", rf_importance.head(10))\n",
    "print(\"XGBoost Top 10 Features:\\n\", xg_importance.head(10))\n",
    "\n",
    "# Save models and scalers\n",
    "with open('backend/model_RF.pkl', 'wb') as f:\n",
    "    pickle.dump(model_rf, f)\n",
    "with open('backend/model_xg.pkl', 'wb') as f:\n",
    "    pickle.dump(model_xg, f)\n",
    "with open('backend/feature_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_scaler, f)\n",
    "with open('backend/target_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(target_scaler, f)\n",
    "\n",
    "# Save mappings\n",
    "mappings = {\n",
    "    'Gender': {'Male': 1, 'Female': 0},\n",
    "    'EducationBackground': {'Life Sciences': 1, 'Marketing': 2, 'Medical': 3, 'Other': 4, 'Technical Degree': 5, 'Human Resources': 6},\n",
    "    'MaritalStatus': {'Single': 1, 'Married': 2, 'Divorced': 3},\n",
    "    'EmpDepartment': {'Sales': 1, 'Human Resources': 2, 'Development': 3, 'Data Science': 4, 'Research & Development': 5, 'Finance': 6},\n",
    "    'EmpJobRole': {'Sales Executive': 1, 'Developer': 2, 'Manager': 3, 'Research Scientist': 4, 'Human Resources': 5, 'Senior Developer': 6, 'Data Scientist': 7, 'Sales Representative': 8, 'Laboratory Technician': 9, 'Senior Manager R&D': 10, 'Finance Manager': 11, 'Technical Architect': 12, 'Business Analyst': 13, 'Technical Lead': 14, 'Research Director': 15, 'Delivery Manager': 16, 'Manager R&D': 17, 'Healthcare Representative': 18, 'Manufacturing Director': 19},\n",
    "    'BusinessTravelFrequency': {'Travel_Rarely': 1, 'Travel_Frequently': 2, 'Non-Travel': 3},\n",
    "    'OverTime': {'Yes': 1, 'No': 0},\n",
    "    'Attrition': {'Yes': 1, 'No': 0}\n",
    "}\n",
    "with open('backend/mappings.pkl', 'wb') as f:\n",
    "    pickle.dump(mappings, f)\n",
    "\n",
    "print(\"Models, scalers, and mappings saved to 'backend/' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
